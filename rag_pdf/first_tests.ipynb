{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFium2Loader(\"../data/allcott.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pvanb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pypdfium2\\_helpers\\textpage.py:81: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the PDF content in a vector database for future retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(docs)\n",
    "type(documents)\n",
    "\n",
    "number_pages = 10 #we only consider the 10 first pages\n",
    "mini_documents = documents[0:number_pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(mini_documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt the LLM using a Retreival chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask your questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The survey authors conducted a nationally representative survey of US adults to investigate partisan differences in beliefs and behaviors related to COVID-19. Here are some additional details about the survey:\n",
      "\n",
      "1. Sample size: The survey was conducted among a sample of 2,000 US adults aged 18 or older.\n",
      "2. Data collection method: The survey was administered online using Amazon's Mechanical Turk platform.\n",
      "3. Survey duration: The survey took approximately 20-30 minutes to complete.\n",
      "4. Data collection period: The survey was conducted between March 27th and April 10th, 2020.\n",
      "5. Response rate: The response rate for the survey was approximately 70%.\n",
      "6. Demographic characteristics: The sample was weighted to be representative of the US adult population based on demographic characteristics such as age, gender, race, and education level.\n",
      "7. Questionnaire design: The survey included a mix of questions about beliefs and behaviors related to COVID-19, including:\n",
      "\t* Beliefs about the severity of COVID-19 and its spread in the US\n",
      "\t* Perceived effectiveness of social distancing measures in preventing the spread of COVID-19\n",
      "\t* Self-reported contact reduction due to COVID-19\n",
      "\t* Predictions about future COVID-19 cases\n",
      "\t* Political ideology (party affiliation)\n",
      "8. Incentives: To encourage honest responses, the survey offered a small financial incentive for completing the survey.\n",
      "9. Validity and reliability: The survey was designed to measure beliefs and behaviors related to COVID-19 with good validity and reliability. The authors assessed the validity of the survey questions through pretesting and made adjustments as needed.\n",
      "10. Statistical analysis: The authors analyzed the survey data using statistical techniques such as regression analysis and propensity score matching to control for potential biases and confounding variables.\n",
      "\n",
      "These details provide a better understanding of the survey design and methods used by the authors in their study on partisan differences in responses to COVID-19.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"could you give me more details about the survey authors conducted?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step : ask more precise questions and some output format in JSON to get same formatting across all papers\n",
    "\n",
    "# string where we take all text contents and apply output parser (see file only_with_string.ipynb, but does not work that well yet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
